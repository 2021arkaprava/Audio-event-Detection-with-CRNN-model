{
  "nbformat": 4,
  "nbformat_minor": 5,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10"
    },
    "colab": {
      "name": "CRNN_model.ipynb",
      "provenance": []
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "93d11d4f",
        "outputId": "da09d944-6d63-40e2-c89a-a7acebcf0fc1"
      },
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive/')"
      ],
      "id": "93d11d4f",
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/gdrive/; to attempt to forcibly remount, call drive.mount(\"/content/gdrive/\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d1be4028"
      },
      "source": [
        "# Functions definitons."
      ],
      "id": "d1be4028"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fc6d606e"
      },
      "source": [
        "def normalization(x):\n",
        "    return (x - np.mean(x, axis = 0))/np.std(x, axis = 0)\n",
        "\n",
        "def frameToTime(frame):\n",
        "    time = frame*(10/313)\n",
        "    return time\n",
        "\n",
        "def HardClassAssign(y_pred):\n",
        "    y_pred_labels = np.argmax(y_pred,axis = 2)\n",
        "\n",
        "    y_labels = np.zeros(y_pred.shape)\n",
        "    for i in range(y_labels.shape[0]):\n",
        "        for j in range(y_labels.shape[1]):\n",
        "            y_labels[i,j, y_pred_labels[i,j]] = 1\n",
        "\n",
        "    return y_labels\n",
        "\n",
        "def audio_tag(y_pred):\n",
        "    count_speech = 0\n",
        "    count_music = 0\n",
        "    y_audio = []\n",
        "    for i in range(y_pred.shape[0]):\n",
        "        for j in range(y_pred.shape[1]):\n",
        "            if (np.array([0., 1., 0.]) == y_pred[i,:]).all():\n",
        "                count_speech = count_speech+1\n",
        "\n",
        "            elif (np.array([1., 0., 0.]) == y_pred[i,:]).all():\n",
        "                count_music = count_music+1\n",
        "                \n",
        "    if count_music == 0 and count_speech != 0:\n",
        "        y_audio = [0,1]\n",
        "    elif count_music != 0 and count_speech == 0:\n",
        "        y_audio = [1,0]\n",
        "    else:\n",
        "        y_audio = [1,1]\n",
        "\n",
        "    return np.array(y_audio)"
      ],
      "id": "fc6d606e",
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f64ef649"
      },
      "source": [
        "# Loading the training data, normalizing and shuffling through the batch-wise."
      ],
      "id": "f64ef649"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7d93fcb5"
      },
      "source": [
        "root_dir = '/content/gdrive/My Drive/Colab Notebooks/'\n",
        "x_train = np.load(root_dir+'X_train.npy')\n",
        "y_train = np.load(root_dir+'Y_train.npy')\n",
        "seed = 0\n",
        "np.random.seed(seed)\n",
        "index = np.random.choice(np.arange(x_train.shape[0]), x_train.shape[0], replace = False)\n",
        "x_train = x_train[index,:,:]\n",
        "y_train = y_train[index,:,:]\n",
        "x_train = np.reshape(x_train, [x_train.shape[0], x_train.shape[1], x_train.shape[2], 1])\n",
        "x_train = normalization(x_train)"
      ],
      "id": "7d93fcb5",
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "de0fe3ca"
      },
      "source": [
        "# Loading validation data and normalizing."
      ],
      "id": "de0fe3ca"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "92ffef4e"
      },
      "source": [
        "x_val = np.load(root_dir+'X_val.npy')\n",
        "y_val = np.load(root_dir+'Y_val.npy')\n",
        "x_val = np.reshape(x_val, [x_val.shape[0], x_val.shape[1], x_val.shape[2], 1])\n",
        "x_val = normalization(x_val)"
      ],
      "id": "92ffef4e",
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f83665a7"
      },
      "source": [
        "# converting to compatible datatypes for processing\n",
        "y_train = y_train.astype(dtype = 'float32')\n",
        "y_val = y_val.astype(dtype = 'float32')"
      ],
      "id": "f83665a7",
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5583861e"
      },
      "source": [
        "# Convolutional Recurrent Neural Network Model "
      ],
      "id": "5583861e"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f4811698"
      },
      "source": [
        "class crnn_model(tf.keras.models.Model):\n",
        "    def __init__(self, pooling_1, pooling_2, pooling_3, rnn_size, in_shape, num_of_classes):\n",
        "        super(crnn_model, self).__init__()\n",
        "        self.pooling = [pooling_1, pooling_2, pooling_3]\n",
        "        self.rnn_size = rnn_size\n",
        "        self.in_shape = in_shape\n",
        "        \n",
        "        self.conv_1 = tf.keras.layers.Conv2D(filters = 128, kernel_size = (3,3), input_shape = in_shape, padding = 'same')     \n",
        "        self.bn1 = tf.keras.layers.BatchNormalization()     \n",
        "        self.act1 = tf.keras.layers.Activation('relu')\n",
        "        self.max1 = tf.keras.layers.MaxPool2D(pool_size = (pooling_1, 1))\n",
        "        \n",
        "        self.conv_2 = tf.keras.layers.Conv2D(filters = 128, kernel_size = (3,3), padding = 'same')\n",
        "        self.bn2 = tf.keras.layers.BatchNormalization()\n",
        "        self.act2 = tf.keras.layers.Activation('relu')\n",
        "        self.max2 = tf.keras.layers.MaxPool2D(pool_size = (pooling_2, 1))\n",
        "        \n",
        "        self.conv_3 = tf.keras.layers.Conv2D(filters = 128, kernel_size = (3,3), padding = 'same')\n",
        "        self.bn3 = tf.keras.layers.BatchNormalization()\n",
        "        self.act3 = tf.keras.layers.Activation('relu')\n",
        "        self.max3 = tf.keras.layers.MaxPool2D(pool_size = (pooling_3, 1))\n",
        "        \n",
        "        self.rnn1 = tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(rnn_size, return_sequences = True))\n",
        "        self.rnn2 = tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(rnn_size, return_sequences = True))\n",
        "        \n",
        "        self.dense1 = tf.keras.layers.TimeDistributed(tf.keras.layers.Dense(rnn_size * 2))\n",
        "        self.dense2 = tf.keras.layers.TimeDistributed(tf.keras.layers.Dense(num_of_classes, activation = 'sigmoid'))\n",
        "        \n",
        "    def call(self, inputs):\n",
        "        # convolutional layer 1\n",
        "        c0_x = self.conv_1(inputs)\n",
        "        b0_x = self.bn1(c0_x)\n",
        "        a0_x = self.act1(b0_x)\n",
        "        m0_x = self.max1(a0_x)   #pooling is only on frequency bins\n",
        "        \n",
        "        # convolutional layer 2\n",
        "        c1_x = self.conv_2(m0_x)\n",
        "        b1_x = self.bn2(c1_x)\n",
        "        a1_x = self.act2(b1_x)\n",
        "        m1_x = self.max2(a1_x)\n",
        "        \n",
        "        # convolutional layer 3\n",
        "        c2_x = self.conv_3(m1_x)\n",
        "        b2_x = self.bn3(c2_x)\n",
        "        a2_x = self.act3(b2_x)\n",
        "        m2_x = self.max3(a2_x) \n",
        "        \n",
        "        #reshaping output for rnn input\n",
        "        p_x = tf.reshape(m2_x, [-1, 4, 128, 313])\n",
        "        re_x = tf.reshape(p_x, [-1, 313, 512])\n",
        "        \n",
        "        #rnn layers\n",
        "        r1_x = self.rnn1(re_x)\n",
        "        r2_x = self.rnn2(r1_x)                                     \n",
        "        \n",
        "        #output hidden dense layer 1\n",
        "        r2_x = self.dense1(r2_x)                                                   \n",
        "        \n",
        "        #final dense layer for output\n",
        "        frame_level_prob = self.dense2(r2_x)\n",
        "        \n",
        "        return frame_level_prob"
      ],
      "id": "f4811698",
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b84dd0fb"
      },
      "source": [
        "# defining the parameters for architecture of the model\n",
        "pool_1 = 4\n",
        "pool_2 = 4\n",
        "pool_3 = 2\n",
        "rnn_len = 32\n",
        "input_shape = (-1, 128, 313, 1)\n",
        "num_class = 3"
      ],
      "id": "b84dd0fb",
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "995f3b88"
      },
      "source": [
        "# instantiating the model\n",
        "crnn = crnn_model(pool_1, pool_2, pool_3, rnn_len, input_shape, num_class)"
      ],
      "id": "995f3b88",
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cc06275c"
      },
      "source": [
        "# defining the loss function and accuracy metric\n",
        "def f1(ground_truth, predicted):\n",
        "    predicted = tf.keras.backend.round(predicted) \n",
        "    \n",
        "    true_positive = tf.keras.backend.sum(tf.keras.backend.cast(ground_truth*predicted, 'float'), axis=0)\n",
        "    true_negative = tf.keras.backend.sum(tf.keras.backend.cast((1-ground_truth)*(1-predicted), 'float'), axis=0)\n",
        "    false_positive = tf.keras.backend.sum(tf.keras.backend.cast((1-ground_truth)*predicted, 'float'), axis=0)\n",
        "    false_negative = tf.keras.backend.sum(tf.keras.backend.cast(ground_truth*(1-predicted), 'float'), axis=0)\n",
        "\n",
        "    precision = true_positive / (true_positive + false_positive + tf.keras.backend.epsilon())\n",
        "    recall = true_positive / (true_positive + false_negative + tf.keras.backend.epsilon())\n",
        "\n",
        "    f1 = 2*precision*recall / (precision+recall+tf.keras.backend.epsilon())\n",
        "    f1 = tf.where(tf.math.is_nan(f1), tf.zeros_like(f1), f1)\n",
        "    return tf.keras.backend.mean(f1)\n",
        "\n",
        "def f1_loss(ground_truth, predicted):\n",
        "    \n",
        "    true_positive = tf.keras.backend.sum(tf.keras.backend.cast(ground_truth*predicted, 'float'), axis=0)\n",
        "    true_negative = tf.keras.backend.sum(tf.keras.backend.cast((1-ground_truth)*(1-predicted), 'float'), axis=0)\n",
        "    false_positive = tf.keras.backend.sum(tf.keras.backend.cast((1-ground_truth)*predicted, 'float'), axis=0)\n",
        "    false_negative = tf.keras.backend.sum(tf.keras.backend.cast(ground_truth*(1-predicted), 'float'), axis=0)\n",
        "\n",
        "    precision = true_positive / (true_positive + false_positive + tf.keras.backend.epsilon())\n",
        "    recall = true_positive / (true_positive + false_negative + tf.keras.backend.epsilon())\n",
        "\n",
        "    f1 = 2*precision*recall / (precision+recall+tf.keras.backend.epsilon())\n",
        "    f1 = tf.where(tf.math.is_nan(f1), tf.zeros_like(f1), f1)\n",
        "    return 1 - tf.keras.backend.mean(f1)"
      ],
      "id": "cc06275c",
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "47897d68"
      },
      "source": [
        "# compiling the model\n",
        "crnn.compile(optimizer=tf.keras.optimizers.Adam(),\n",
        "              loss=f1_loss, metrics=['accuracy', f1])"
      ],
      "id": "47897d68",
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a31be2dd"
      },
      "source": [
        "### Training the CRNN model"
      ],
      "id": "a31be2dd"
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "08dbf2f7",
        "outputId": "8100c8a6-a5cf-476f-f1d9-403b0e6c80cc"
      },
      "source": [
        "crnn.fit(x_train, y_train, epochs = 10, validation_data=(x_val, y_val))"
      ],
      "id": "08dbf2f7",
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "53/53 [==============================] - 25s 461ms/step - loss: 0.3924 - accuracy: 0.5398 - f1: 0.6076 - val_loss: 0.5785 - val_accuracy: 0.3671 - val_f1: 0.4226\n",
            "Epoch 2/10\n",
            "53/53 [==============================] - 24s 459ms/step - loss: 0.3894 - accuracy: 0.5322 - f1: 0.6110 - val_loss: 0.5804 - val_accuracy: 0.3504 - val_f1: 0.4197\n",
            "Epoch 3/10\n",
            "53/53 [==============================] - 24s 458ms/step - loss: 0.4040 - accuracy: 0.5153 - f1: 0.5966 - val_loss: 0.7315 - val_accuracy: 0.2540 - val_f1: 0.2697\n",
            "Epoch 4/10\n",
            "53/53 [==============================] - 24s 459ms/step - loss: 0.3867 - accuracy: 0.5413 - f1: 0.6130 - val_loss: 0.6151 - val_accuracy: 0.3458 - val_f1: 0.3841\n",
            "Epoch 5/10\n",
            "53/53 [==============================] - 24s 459ms/step - loss: 0.3898 - accuracy: 0.5390 - f1: 0.6098 - val_loss: 0.6073 - val_accuracy: 0.3514 - val_f1: 0.3935\n",
            "Epoch 6/10\n",
            "53/53 [==============================] - 24s 458ms/step - loss: 0.3952 - accuracy: 0.5248 - f1: 0.6050 - val_loss: 0.5930 - val_accuracy: 0.3666 - val_f1: 0.4073\n",
            "Epoch 7/10\n",
            "53/53 [==============================] - 24s 459ms/step - loss: 0.3849 - accuracy: 0.5456 - f1: 0.6154 - val_loss: 0.5920 - val_accuracy: 0.3818 - val_f1: 0.4077\n",
            "Epoch 8/10\n",
            "53/53 [==============================] - 24s 458ms/step - loss: 0.3860 - accuracy: 0.5482 - f1: 0.6137 - val_loss: 0.5724 - val_accuracy: 0.3815 - val_f1: 0.4280\n",
            "Epoch 9/10\n",
            "53/53 [==============================] - 24s 458ms/step - loss: 0.3967 - accuracy: 0.5419 - f1: 0.6040 - val_loss: 0.6560 - val_accuracy: 0.2827 - val_f1: 0.3460\n",
            "Epoch 10/10\n",
            "53/53 [==============================] - 24s 459ms/step - loss: 0.3882 - accuracy: 0.5275 - f1: 0.6127 - val_loss: 0.6859 - val_accuracy: 0.2583 - val_f1: 0.3136\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f9db0275990>"
            ]
          },
          "metadata": {},
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a02516b3",
        "outputId": "223d2dee-8723-4cf5-e70f-2ad363a43e57"
      },
      "source": [
        "# saving weights of the model\n",
        "crnn.save_weights(root_dir+'/crnn_model_weights/CRNN_weights.h5')\n",
        "crnn.summary()"
      ],
      "id": "a02516b3",
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"crnn_model_2\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_6 (Conv2D)           multiple                  1280      \n",
            "                                                                 \n",
            " batch_normalization_6 (Batc  multiple                 512       \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " activation_6 (Activation)   multiple                  0         \n",
            "                                                                 \n",
            " max_pooling2d_6 (MaxPooling  multiple                 0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " conv2d_7 (Conv2D)           multiple                  147584    \n",
            "                                                                 \n",
            " batch_normalization_7 (Batc  multiple                 512       \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " activation_7 (Activation)   multiple                  0         \n",
            "                                                                 \n",
            " max_pooling2d_7 (MaxPooling  multiple                 0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " conv2d_8 (Conv2D)           multiple                  147584    \n",
            "                                                                 \n",
            " batch_normalization_8 (Batc  multiple                 512       \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " activation_8 (Activation)   multiple                  0         \n",
            "                                                                 \n",
            " max_pooling2d_8 (MaxPooling  multiple                 0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " bidirectional_4 (Bidirectio  multiple                 139520    \n",
            " nal)                                                            \n",
            "                                                                 \n",
            " bidirectional_5 (Bidirectio  multiple                 24832     \n",
            " nal)                                                            \n",
            "                                                                 \n",
            " time_distributed_4 (TimeDis  multiple                 4160      \n",
            " tributed)                                                       \n",
            "                                                                 \n",
            " time_distributed_5 (TimeDis  multiple                 195       \n",
            " tributed)                                                       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 466,691\n",
            "Trainable params: 465,923\n",
            "Non-trainable params: 768\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j2yYKi0wHgs5"
      },
      "source": [
        "# Loading and normalizing test data."
      ],
      "id": "j2yYKi0wHgs5"
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "64lOnuD6Hn5u",
        "outputId": "8e77fcde-1eac-441e-ea8a-6c686bd6edee"
      },
      "source": [
        "x_test = np.load(root_dir+'/x_test.npy')\n",
        "x_test = np.reshape(x_test, [x_test.shape[0], x_test.shape[1], x_test.shape[2], 1])\n",
        "x_test = normalization(x_test)\n",
        "print(x_test.shape)"
      ],
      "id": "64lOnuD6Hn5u",
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(100, 128, 313, 1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "18f5cd5d"
      },
      "source": [
        "# Predicting with the model"
      ],
      "id": "18f5cd5d"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "95eb91e7"
      },
      "source": [
        "y_pred = crnn.predict(x_test)\n",
        "\n",
        "\n",
        "y_pred = HardClassAssign(y_pred)"
      ],
      "id": "95eb91e7",
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "234c9ae1"
      },
      "source": [
        "# Sound event detection"
      ],
      "id": "234c9ae1"
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c47c0870",
        "outputId": "7ed0a39d-5b4a-42e4-e658-dd9b04718bc8"
      },
      "source": [
        "n_batches = y_pred.shape[0]\n",
        "n_frames = y_pred.shape[1]\n",
        "i = 0\n",
        "j = 0\n",
        "start_music = 0\n",
        "end_music = 0\n",
        "start_speech = 0\n",
        "end_speech = 0\n",
        "name = 'test_sample-'\n",
        "print('filename,event,onset,offset')\n",
        "while j<n_batches:\n",
        "    i=0\n",
        "    start_music = 0\n",
        "    end_music = 0\n",
        "    start_speech = 0\n",
        "    end_speech = 0\n",
        "    temp = y_pred[j,:,:]\n",
        "    temp = temp.astype(dtype='int')\n",
        "    while i<n_frames-1:\n",
        "        if (temp[i+1,:] == np.array([1,0,0])).all() and (temp[i,:] == np.array([0,0,1])).all():\n",
        "            start_music = frameToTime(i+1)\n",
        "        elif (temp[i,:] == np.array([1,0,0])).all() and (temp[i+1,:] == np.array([0,0,1])).all():\n",
        "            end_music = frameToTime(i)\n",
        "            print(name+str(j)+',Music,'+str(start_music)+','+str(end_music))\n",
        "        elif (temp[i+1,:] == np.array([0,1,0])).all() and (temp[i,:] == np.array([0,0,1])).all():\n",
        "            start_speech = frameToTime(i+1)\n",
        "        elif (temp[i,:] == np.array([0,1,0])).all() and (temp[i+1,:] == np.array([0,0,1])).all():\n",
        "            end_speech = frameToTime(i)\n",
        "            print(name+str(j)+',Speech,'+str(start_speech)+','+str(end_speech))\n",
        "        \n",
        "        i = i+1\n",
        "        \n",
        "    j=j+1"
      ],
      "id": "c47c0870",
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "filename,event,onset,offset\n",
            "test_sample-0,Speech,0,9.648562300319488\n",
            "test_sample-1,Music,0,0.22364217252396165\n",
            "test_sample-1,Speech,2.0127795527156547,9.233226837060702\n",
            "test_sample-2,Music,0,5.5910543130990416\n",
            "test_sample-2,Speech,8.051118210862619,9.648562300319488\n",
            "test_sample-3,Music,0,0.3194888178913738\n",
            "test_sample-3,Speech,2.0447284345047922,9.26517571884984\n",
            "test_sample-4,Music,0,5.143769968051118\n",
            "test_sample-4,Speech,7.444089456869009,9.233226837060702\n",
            "test_sample-5,Speech,0,9.648562300319488\n",
            "test_sample-6,Music,0,0.8626198083067093\n",
            "test_sample-6,Speech,5.015974440894569,5.079872204472843\n",
            "test_sample-6,Speech,6.3897763578274756,6.741214057507987\n",
            "test_sample-6,Speech,6.805111821086261,9.648562300319488\n",
            "test_sample-7,Music,0,3.961661341853035\n",
            "test_sample-7,Speech,5.175718849840256,6.261980830670926\n",
            "test_sample-7,Speech,7.380191693290734,8.945686900958465\n",
            "test_sample-8,Music,0,4.440894568690096\n",
            "test_sample-9,Music,0,9.00958466453674\n",
            "test_sample-10,Music,0,5.079872204472843\n",
            "test_sample-10,Speech,7.539936102236421,8.722044728434504\n",
            "test_sample-11,Speech,0,9.648562300319488\n",
            "test_sample-12,Music,0,8.083067092651756\n",
            "test_sample-12,Speech,9.073482428115016,9.329073482428115\n",
            "test_sample-13,Music,0,1.9169329073482428\n",
            "test_sample-13,Speech,5.303514376996805,9.776357827476039\n",
            "test_sample-14,Music,0,6.134185303514377\n",
            "test_sample-14,Speech,8.498402555910543,9.808306709265175\n",
            "test_sample-15,Music,0,5.0479233226837055\n",
            "test_sample-15,Speech,7.507987220447284,8.977635782747603\n",
            "test_sample-16,Speech,0,9.648562300319488\n",
            "test_sample-17,Music,0,8.115015974440894\n",
            "test_sample-17,Speech,9.13738019169329,9.680511182108626\n",
            "test_sample-18,Speech,0,9.648562300319488\n",
            "test_sample-19,Music,0,4.2492012779552715\n",
            "test_sample-19,Speech,7.220447284345048,9.648562300319488\n",
            "test_sample-20,Speech,0,9.201277955271564\n",
            "test_sample-21,Music,0,5.367412140575079\n",
            "test_sample-21,Speech,7.348242811501597,9.776357827476039\n",
            "test_sample-22,Music,0,7.444089456869009\n",
            "test_sample-22,Speech,9.13738019169329,9.584664536741213\n",
            "test_sample-23,Music,0,0.8626198083067093\n",
            "test_sample-23,Speech,2.268370607028754,8.977635782747603\n",
            "test_sample-24,Music,0,3.3865814696485623\n",
            "test_sample-24,Speech,6.006389776357827,6.198083067092652\n",
            "test_sample-24,Speech,6.996805111821086,9.073482428115016\n",
            "test_sample-25,Music,0,3.0031948881789137\n",
            "test_sample-25,Speech,4.984025559105431,9.233226837060702\n",
            "test_sample-26,Speech,0,9.648562300319488\n",
            "test_sample-27,Speech,0,1.2779552715654952\n",
            "test_sample-27,Speech,1.7252396166134185,9.744408945686901\n",
            "test_sample-28,Speech,0,1.3738019169329072\n",
            "test_sample-28,Speech,1.5654952076677315,9.201277955271564\n",
            "test_sample-29,Music,0,5.84664536741214\n",
            "test_sample-30,Music,0,1.8849840255591053\n",
            "test_sample-30,Speech,3.8977635782747604,9.424920127795527\n",
            "test_sample-30,Speech,9.584664536741213,9.648562300319488\n",
            "test_sample-31,Music,0,0.38338658146964855\n",
            "test_sample-31,Speech,2.0447284345047922,9.712460063897764\n",
            "test_sample-32,Speech,0,9.648562300319488\n",
            "test_sample-33,Music,0,0.5431309904153354\n",
            "test_sample-33,Speech,2.108626198083067,9.329073482428115\n",
            "test_sample-34,Music,0,4.760383386581469\n",
            "test_sample-34,Speech,7.380191693290734,9.297124600638977\n",
            "test_sample-35,Music,0,3.3546325878594248\n",
            "test_sample-35,Speech,4.760383386581469,9.744408945686901\n",
            "test_sample-36,Music,0,0.926517571884984\n",
            "test_sample-36,Speech,2.8115015974440896,9.456869009584665\n",
            "test_sample-36,Speech,9.520766773162938,9.648562300319488\n",
            "test_sample-37,Music,0,7.412140575079872\n",
            "test_sample-37,Speech,9.041533546325878,9.712460063897764\n",
            "test_sample-38,Music,0,9.13738019169329\n",
            "test_sample-39,Music,0,8.30670926517572\n",
            "test_sample-40,Speech,0,9.616613418530351\n",
            "test_sample-41,Music,0,5.111821086261981\n",
            "test_sample-41,Speech,7.763578274760383,9.13738019169329\n",
            "test_sample-41,Speech,9.712460063897764,9.712460063897764\n",
            "test_sample-41,Speech,9.840255591054312,9.904153354632587\n",
            "test_sample-42,Speech,0,9.648562300319488\n",
            "test_sample-43,Music,0,5.335463258785942\n",
            "test_sample-43,Speech,8.594249201277956,8.753993610223642\n",
            "test_sample-43,Speech,9.073482428115016,9.616613418530351\n",
            "test_sample-44,Music,0,0.6389776357827476\n",
            "test_sample-44,Speech,2.1725239616613417,2.2044728434504792\n",
            "test_sample-44,Speech,2.268370607028754,2.268370607028754\n",
            "test_sample-44,Speech,2.3961661341853033,9.39297124600639\n",
            "test_sample-45,Music,0,6.805111821086261\n",
            "test_sample-45,Speech,8.274760383386582,9.39297124600639\n",
            "test_sample-46,Music,0,0.7028753993610224\n",
            "test_sample-46,Speech,2.1405750798722045,9.105431309904153\n",
            "test_sample-47,Music,0,3.1948881789137378\n",
            "test_sample-47,Speech,4.824281150159744,9.744408945686901\n",
            "test_sample-48,Speech,0,9.776357827476039\n",
            "test_sample-49,Music,0,9.488817891373802\n",
            "test_sample-50,Music,0,1.0862619808306708\n",
            "test_sample-50,Music,1.6932907348242812,9.904153354632587\n",
            "test_sample-51,Music,0,4.824281150159744\n",
            "test_sample-51,Speech,9.520766773162938,9.744408945686901\n",
            "test_sample-52,Music,0,3.099041533546326\n",
            "test_sample-52,Speech,4.792332268370607,4.792332268370607\n",
            "test_sample-52,Speech,4.888178913738019,9.201277955271564\n",
            "test_sample-53,Music,0,2.0127795527156547\n",
            "test_sample-53,Music,2.108626198083067,6.773162939297125\n",
            "test_sample-53,Music,7.092651757188498,8.051118210862619\n",
            "test_sample-53,Speech,9.329073482428115,9.329073482428115\n",
            "test_sample-54,Music,0,6.261980830670926\n",
            "test_sample-54,Speech,9.13738019169329,9.712460063897764\n",
            "test_sample-55,Music,0,8.753993610223642\n",
            "test_sample-56,Music,0,1.8210862619808306\n",
            "test_sample-56,Speech,4.345047923322683,9.648562300319488\n",
            "test_sample-57,Speech,0,9.744408945686901\n",
            "test_sample-58,Speech,0,1.2460063897763578\n",
            "test_sample-58,Speech,1.6932907348242812,9.329073482428115\n",
            "test_sample-59,Music,0,3.5143769968051117\n",
            "test_sample-59,Speech,4.856230031948882,5.271565495207668\n",
            "test_sample-59,Speech,6.3897763578274756,6.7092651757188495\n",
            "test_sample-59,Speech,6.773162939297125,9.648562300319488\n",
            "test_sample-60,Music,0,8.115015974440894\n",
            "test_sample-60,Speech,9.233226837060702,9.361022364217252\n",
            "test_sample-61,Music,0,9.87220447284345\n",
            "test_sample-62,Music,0,6.006389776357827\n",
            "test_sample-63,Music,0,7.731629392971246\n",
            "test_sample-63,Speech,9.26517571884984,9.552715654952076\n",
            "test_sample-63,Speech,9.648562300319488,9.680511182108626\n",
            "test_sample-64,Music,0,8.274760383386582\n",
            "test_sample-65,Speech,0,9.776357827476039\n",
            "test_sample-66,Speech,0,9.648562300319488\n",
            "test_sample-67,Speech,1.8849840255591053,9.201277955271564\n",
            "test_sample-68,Music,0,9.520766773162938\n",
            "test_sample-69,Music,0,3.610223642172524\n",
            "test_sample-69,Speech,5.431309904153355,9.424920127795527\n",
            "test_sample-70,Music,0,9.808306709265175\n",
            "test_sample-71,Music,0,1.0543130990415335\n",
            "test_sample-71,Music,1.5974440894568689,5.175718849840256\n",
            "test_sample-71,Music,5.559105431309904,8.498402555910543\n",
            "test_sample-71,Music,8.562300319488818,9.712460063897764\n",
            "test_sample-72,Music,0,3.1629392971246006\n",
            "test_sample-72,Music,4.50479233226837,4.760383386581469\n",
            "test_sample-72,Speech,7.8274760383386575,9.712460063897764\n",
            "test_sample-73,Music,0,6.230031948881789\n",
            "test_sample-73,Speech,8.945686900958465,9.712460063897764\n",
            "test_sample-74,Music,0,9.456869009584665\n",
            "test_sample-75,Music,0,3.2268370607028753\n",
            "test_sample-75,Speech,4.888178913738019,6.134185303514377\n",
            "test_sample-75,Speech,6.517571884984025,9.297124600638977\n",
            "test_sample-76,Speech,0,9.744408945686901\n",
            "test_sample-77,Speech,0,9.648562300319488\n",
            "test_sample-78,Speech,0,9.648562300319488\n",
            "test_sample-79,Music,0,2.0127795527156547\n",
            "test_sample-79,Music,2.1405750798722045,2.364217252396166\n",
            "test_sample-79,Music,2.460063897763578,6.837060702875399\n",
            "test_sample-79,Music,7.060702875399361,8.051118210862619\n",
            "test_sample-79,Speech,9.13738019169329,9.488817891373802\n",
            "test_sample-80,Music,0,4.440894568690096\n",
            "test_sample-80,Speech,8.53035143769968,9.744408945686901\n",
            "test_sample-81,Music,0,4.696485623003195\n",
            "test_sample-81,Speech,6.677316293929712,9.808306709265175\n",
            "test_sample-82,Music,0,5.7507987220447285\n",
            "test_sample-82,Speech,7.31629392971246,8.338658146964855\n",
            "test_sample-83,Music,0,7.476038338658147\n",
            "test_sample-83,Music,7.603833865814696,7.731629392971246\n",
            "test_sample-83,Speech,9.169329073482428,9.680511182108626\n",
            "test_sample-84,Music,0,0.2875399361022364\n",
            "test_sample-84,Speech,2.0127795527156547,9.233226837060702\n",
            "test_sample-85,Music,0,3.0031948881789137\n",
            "test_sample-85,Speech,4.888178913738019,9.201277955271564\n",
            "test_sample-86,Music,0,1.0223642172523961\n",
            "test_sample-86,Music,1.4376996805111821,9.808306709265175\n",
            "test_sample-87,Music,0,4.63258785942492\n",
            "test_sample-87,Speech,6.166134185303514,9.648562300319488\n",
            "test_sample-88,Music,0,0.6389776357827476\n",
            "test_sample-88,Speech,6.134185303514377,6.645367412140574\n",
            "test_sample-88,Speech,6.805111821086261,9.201277955271564\n",
            "test_sample-89,Music,0,1.5015974440894568\n",
            "test_sample-89,Speech,3.3546325878594248,9.297124600638977\n",
            "test_sample-90,Music,0,5.9105431309904155\n",
            "test_sample-90,Speech,8.338658146964855,9.616613418530351\n",
            "test_sample-91,Music,0,0.4153354632587859\n",
            "test_sample-91,Speech,2.1405750798722045,9.456869009584665\n",
            "test_sample-91,Speech,9.520766773162938,9.680511182108626\n",
            "test_sample-92,Music,0,9.87220447284345\n",
            "test_sample-93,Music,0,7.955271565495208\n",
            "test_sample-94,Music,0,4.920127795527156\n",
            "test_sample-95,Music,0,9.616613418530351\n",
            "test_sample-96,Music,0,0.03194888178913738\n",
            "test_sample-96,Speech,1.9169329073482428,9.648562300319488\n",
            "test_sample-97,Music,0,9.488817891373802\n",
            "test_sample-98,Music,0,0.9584664536741214\n",
            "test_sample-98,Speech,2.364217252396166,8.753993610223642\n",
            "test_sample-99,Speech,0,9.616613418530351\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "886bfc75"
      },
      "source": [
        "# Audio Tagging"
      ],
      "id": "886bfc75"
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5e394c78",
        "outputId": "8acda55a-1d14-4239-dc9a-e8436dfad6c7"
      },
      "source": [
        "y_label = y_pred\n",
        "y_aud = []\n",
        "for i in range(y_label.shape[0]):\n",
        "    temp = audio_tag(y_label[i,:,:])\n",
        "    y_aud.append(temp)\n",
        "\n",
        "y_aud = np.array(y_aud)\n",
        "n_batches = y_aud.shape[0]\n",
        "i = 0\n",
        "j = 0\n",
        "name = 'test_sample-'\n",
        "print('filename,Music,Speech')\n",
        "while i<n_batches:\n",
        "    if (y_aud[i,:] == np.array([1,0])).all():\n",
        "        print(name+str(i)+',1,0')\n",
        "    elif (y_aud[i,:] == np.array([0,1])).all():\n",
        "        print(name+str(i)+',0,1')\n",
        "    elif (y_aud[i,:] == np.array([1,1])).all():\n",
        "        print(name+str(i)+',1,1')\n",
        "    i=i+1"
      ],
      "id": "5e394c78",
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "filename,Music,Speech\n",
            "test_sample-0,0,1\n",
            "test_sample-1,1,1\n",
            "test_sample-2,1,1\n",
            "test_sample-3,1,1\n",
            "test_sample-4,1,1\n",
            "test_sample-5,0,1\n",
            "test_sample-6,1,1\n",
            "test_sample-7,1,1\n",
            "test_sample-8,1,0\n",
            "test_sample-9,1,0\n",
            "test_sample-10,1,1\n",
            "test_sample-11,0,1\n",
            "test_sample-12,1,1\n",
            "test_sample-13,1,1\n",
            "test_sample-14,1,1\n",
            "test_sample-15,1,1\n",
            "test_sample-16,0,1\n",
            "test_sample-17,1,1\n",
            "test_sample-18,0,1\n",
            "test_sample-19,1,1\n",
            "test_sample-20,0,1\n",
            "test_sample-21,1,1\n",
            "test_sample-22,1,1\n",
            "test_sample-23,1,1\n",
            "test_sample-24,1,1\n",
            "test_sample-25,1,1\n",
            "test_sample-26,0,1\n",
            "test_sample-27,0,1\n",
            "test_sample-28,0,1\n",
            "test_sample-29,1,0\n",
            "test_sample-30,1,1\n",
            "test_sample-31,1,1\n",
            "test_sample-32,0,1\n",
            "test_sample-33,1,1\n",
            "test_sample-34,1,1\n",
            "test_sample-35,1,1\n",
            "test_sample-36,1,1\n",
            "test_sample-37,1,1\n",
            "test_sample-38,1,0\n",
            "test_sample-39,1,0\n",
            "test_sample-40,0,1\n",
            "test_sample-41,1,1\n",
            "test_sample-42,0,1\n",
            "test_sample-43,1,1\n",
            "test_sample-44,1,1\n",
            "test_sample-45,1,1\n",
            "test_sample-46,1,1\n",
            "test_sample-47,1,1\n",
            "test_sample-48,0,1\n",
            "test_sample-49,1,0\n",
            "test_sample-50,1,0\n",
            "test_sample-51,1,1\n",
            "test_sample-52,1,1\n",
            "test_sample-53,1,1\n",
            "test_sample-54,1,1\n",
            "test_sample-55,1,0\n",
            "test_sample-56,1,1\n",
            "test_sample-57,0,1\n",
            "test_sample-58,0,1\n",
            "test_sample-59,1,1\n",
            "test_sample-60,1,1\n",
            "test_sample-61,1,0\n",
            "test_sample-62,1,0\n",
            "test_sample-63,1,1\n",
            "test_sample-64,1,0\n",
            "test_sample-65,0,1\n",
            "test_sample-66,0,1\n",
            "test_sample-67,0,1\n",
            "test_sample-68,1,0\n",
            "test_sample-69,1,1\n",
            "test_sample-70,1,0\n",
            "test_sample-71,1,0\n",
            "test_sample-72,1,1\n",
            "test_sample-73,1,1\n",
            "test_sample-74,1,0\n",
            "test_sample-75,1,1\n",
            "test_sample-76,0,1\n",
            "test_sample-77,0,1\n",
            "test_sample-78,0,1\n",
            "test_sample-79,1,1\n",
            "test_sample-80,1,1\n",
            "test_sample-81,1,1\n",
            "test_sample-82,1,1\n",
            "test_sample-83,1,1\n",
            "test_sample-84,1,1\n",
            "test_sample-85,1,1\n",
            "test_sample-86,1,0\n",
            "test_sample-87,1,1\n",
            "test_sample-88,1,1\n",
            "test_sample-89,1,1\n",
            "test_sample-90,1,1\n",
            "test_sample-91,1,1\n",
            "test_sample-92,1,0\n",
            "test_sample-93,1,0\n",
            "test_sample-94,1,0\n",
            "test_sample-95,1,0\n",
            "test_sample-96,1,1\n",
            "test_sample-97,1,0\n",
            "test_sample-98,1,1\n",
            "test_sample-99,0,1\n"
          ]
        }
      ]
    }
  ]
}