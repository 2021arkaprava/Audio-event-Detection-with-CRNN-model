{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "611a4137",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/thish/Documents/Project/thish_env/lib/python3.8/site-packages/pydub/utils.py:170: RuntimeWarning: Couldn't find ffmpeg or avconv - defaulting to ffmpeg, but may not work\n",
      "  warn(\"Couldn't find ffmpeg or avconv - defaulting to ffmpeg, but may not work\", RuntimeWarning)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import librosa\n",
    "import soundfile as sf\n",
    "from pydub import AudioSegment\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c40dc687",
   "metadata": {},
   "source": [
    "# Function Definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a46e7df7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def readAudio(filename):\n",
    "    x, sr = librosa.load(filename, sr=16000)\n",
    "    return x, sr\n",
    "\n",
    "#calculate spectrogram\n",
    "def calc_spec(x):\n",
    "    n_fft = 1024\n",
    "    hop_length = 512\n",
    "    win_length = 1024\n",
    "    X = np.abs(librosa.stft(x, n_fft = n_fft, hop_length = hop_length, win_length = win_length, window='hann', dtype = np.complex256))\n",
    "    X = librosa.power_to_db(X**2,ref=np.max)\n",
    "    return X\n",
    "\n",
    "def saveSpectrogram(X, outfilename):\n",
    "    assert outfilename[-4:]=='.npy'  #'outfilename extension should be .npy'\n",
    "    np.save(outfilename, X)\n",
    "    return\n",
    "\n",
    "def readSpectrogram(infilename):\n",
    "    X = np.load(infilename)\n",
    "    return X\n",
    "\n",
    "def conv_to_mono(inFile,outFile):\n",
    "    sound = AudioSegment.from_wav(inFile)\n",
    "    sound = sound.set_channels(1)\n",
    "    sound.export(outFile, format=\"wav\")\n",
    "    return\n",
    "\n",
    "def store_to_npy(inFile, outFile):\n",
    "    x, sr = librosa.load(inFile, sr=16000)\n",
    "    assert outFile[-4:]=='.npy'  #'outfilename extension should be .npy'\n",
    "    np.save(outFile, x)\n",
    "    return\n",
    "\n",
    "def read_from_npy(inFile):\n",
    "    X = np.load(inFile)\n",
    "    return X\n",
    "\n",
    "def write_npy_to_wav(x, outFile):\n",
    "    sf.write(outFile, x, 16000, 'PCM_24')\n",
    "    return\n",
    "\n",
    "def start_time(lamb_1= 1.71111):\n",
    "    t_start = 0\n",
    "    while t_start < 1:\n",
    "        t_start = np.random.exponential(1/lamb_1)\n",
    "    return t_start\n",
    "\n",
    "def end_time(lamb_2 = 1.13264):\n",
    "    t_end = 0\n",
    "    while t_end < 1 or t_end > 5:\n",
    "        t_end = np.random.exponential(1/lamb_2)\n",
    "    return t_end\n",
    "\n",
    "def time_to_index(t,sr):\n",
    "    index = int(np.ceil(t*sr))\n",
    "    return index\n",
    "\n",
    "def add_noise(input_array, noise_deviation):\n",
    "    noise = np.random.normal(0, noise_deviation, input_array.shape)\n",
    "    output_array = input_array+noise\n",
    "    return output_array\n",
    "\n",
    "def convert_to_segments(source_array, dest_dir, name,class_name):\n",
    "    column1 = ['filename','onset','offset','class']\n",
    "    df =pd.DataFrame(columns = column1)\n",
    "    mLen = source_array.shape[0]\n",
    "    source_count = 0\n",
    "    file_num = 1\n",
    "    sr = 16000\n",
    "    time_duration = 10\n",
    "    seed = 0\n",
    "    np.random.seed(seed)\n",
    "    N = sr*time_duration\n",
    "    noise_stdd = 0.001\n",
    "    # generating the audio files of music only\n",
    "    while source_count < mLen:\n",
    "        #print(\"File Number - \",file_num)\n",
    "        t1 = 0\n",
    "        start =  0\n",
    "        end = 0\n",
    "        samples_to_write = np.zeros(N)\n",
    "        #segment = 0\n",
    "        while t1<10:\n",
    "            #segment = segment + 1\n",
    "            start = t1 + start_time()\n",
    "            if start < 10:\n",
    "                end = start + end_time()\n",
    "                if end < 10:\n",
    "                    t1 = end\n",
    "                else:\n",
    "                    t1 = 10\n",
    "                    \n",
    "                n_samples = int(np.ceil((t1 - start) *sr))\n",
    "                t1_to_index = time_to_index(t1,sr) \n",
    "                #print(\"Segment number : \",segment)\n",
    "                #print(\"start :\", start,\", end :\", end,\", difference :\", t1-start,\", n_samples :\", n_samples,\"\\nstart_sample :\", t1_to_index,\", source samples used : \",source_count,\", total source samples :\", mLen)\n",
    "                #print(\"start :\", start,\"end :\", end,\"difference :\", t1-start,\"n_samples :\", n_samples,\"start_sample :\", t1_to_index)\n",
    "                if(source_count+n_samples < mLen):\n",
    "                    samples_to_write[time_to_index(start,sr):time_to_index(start,sr)+n_samples-1] = source_array[source_count:(source_count+n_samples-1)]\n",
    "                    df = df.append({'filename':name+str(file_num),'onset':start,'offset':t1,'class':class_name}, ignore_index = True)\n",
    "                source_count = source_count+n_samples\n",
    "                #print(\"Segment number : \",segment)\n",
    "                #print(\"start :\", start,\", end :\", end,\", difference :\", t1-start,\", n_samples :\", n_samples,\"\\nstart_sample :\", t1_to_index,\", source samples used : \",source_count,\", total source samples :\", mLen)\n",
    "                #print(\"source samples used : \",source_count,\"total source samples :\", mLen)\n",
    "            else:\n",
    "                t1 = 10\n",
    "        samples_to_write = add_noise(samples_to_write, noise_stdd)\n",
    "        write_npy_to_wav(samples_to_write,dest_dir+name+str(file_num)+\".wav\")\n",
    "        file_num = file_num+1\n",
    "        if(file_num >= 600):\n",
    "            df.to_csv(dest_dir+'labels.csv', index = False)\n",
    "            print(\"Some error has occured, trying to write to too many files.\")\n",
    "            return file_num-1\n",
    "        \n",
    "    df.to_csv(dest_dir+'labels.csv', index = False)   \n",
    "    print(\"Completed. Number of files  written to -\", file_num-1)\n",
    "    return file_num-1\n",
    "\n",
    "def convert_to_mixed_segments(source_array1, source_array2, dest_dir, name):\n",
    "    column1 = ['filename','onset','offset','class']\n",
    "    df =pd.DataFrame(columns = column1)\n",
    "    mLen = source_array1.shape[0]\n",
    "    sLen = source_array2.shape[0]\n",
    "    source_count1 = 0\n",
    "    source_count2 = 0\n",
    "    file_num = 1\n",
    "    sr = 16000\n",
    "    time_duration = 10\n",
    "    seed = 0\n",
    "    np.random.seed(seed)\n",
    "    N = sr*time_duration\n",
    "    noise_stdd = 0.001\n",
    "    # generating the audio files of music and speech\n",
    "    while source_count1 < mLen or source_count2 < sLen:\n",
    "        #print(\"File Number - \",file_num)\n",
    "        t1 = 0\n",
    "        start =  0\n",
    "        end = 0\n",
    "        samples_to_write = np.zeros(N)\n",
    "        #segment = 0\n",
    "        while t1<10:\n",
    "            #segment = segment + 1\n",
    "            start = t1 + start_time()\n",
    "            if start < 10:\n",
    "                end = start + end_time()\n",
    "                if end < 10:\n",
    "                    t1 = end\n",
    "                else:\n",
    "                    t1 = 10\n",
    "                    \n",
    "                n_samples = int(np.ceil((t1 - start) *sr))\n",
    "                t1_to_index = time_to_index(t1,sr)\n",
    "                if np.round(np.random.rand())==0:\n",
    "                    class_name = 'music'\n",
    "                #print(\"Segment number : \",segment)\n",
    "                #print(\"start :\", start,\", end :\", end,\", difference :\", t1-start,\", n_samples :\", n_samples,\"\\nstart_sample :\", t1_to_index,\", source samples used : \",source_count,\", total source samples :\", mLen)\n",
    "                #print(\"start :\", start,\"end :\", end,\"difference :\", t1-start,\"n_samples :\", n_samples,\"start_sample :\", t1_to_index)\n",
    "                    if(source_count1+n_samples < mLen):\n",
    "                        samples_to_write[time_to_index(start,sr):time_to_index(start,sr)+n_samples-1] = source_array1[source_count1:(source_count1+n_samples-1)]\n",
    "                        df = df.append({'filename':name+str(file_num),'onset':start,'offset':t1,'class':class_name}, ignore_index = True)\n",
    "                    source_count1 = source_count1+n_samples\n",
    "                #print(\"Segment number : \",segment)\n",
    "                #print(\"start :\", start,\", end :\", end,\", difference :\", t1-start,\", n_samples :\", n_samples,\"\\nstart_sample :\", t1_to_index,\", source samples used : \",source_count,\", total source samples :\", mLen)\n",
    "                #print(\"source samples used : \",source_count,\"total source samples :\", mLen)\n",
    "                else:\n",
    "                    class_name = 'speech'\n",
    "                    if(source_count2+n_samples < sLen):\n",
    "                        samples_to_write[time_to_index(start,sr):time_to_index(start,sr)+n_samples-1] = source_array2[source_count2:(source_count2+n_samples-1)]\n",
    "                        df = df.append({'filename':name+str(file_num),'onset':start,'offset':t1,'class':class_name}, ignore_index = True)\n",
    "                    source_count2 = source_count2+n_samples   \n",
    "            else:\n",
    "                t1 = 10\n",
    "        samples_to_write = add_noise(samples_to_write, noise_stdd)\n",
    "        write_npy_to_wav(samples_to_write,dest_dir+name+str(file_num)+\".wav\")\n",
    "        file_num = file_num+1\n",
    "        if(file_num >= 600):\n",
    "            df.to_csv(dest_dir+'labels.csv', index = False)\n",
    "            print(\"Some error has occured, trying to write to too many files.\")\n",
    "            return file_num-1\n",
    "    df.to_csv(dest_dir+'labels.csv', index = False)\n",
    "    print(\"Completed. Number of files written to -\", file_num-1)\n",
    "    return file_num-1\n",
    "\n",
    "def conv_to_frame(t,H):\n",
    "    N = int(np.ceil((t*H)/10))\n",
    "    return N\n",
    "\n",
    "def convToLinear(X):\n",
    "    x = np.exp(X/10)\n",
    "    return x\n",
    "    \n",
    "def stftToLogMel(X):\n",
    "    # converts from log power spectrogram to MFCC\n",
    "    fs = 16000\n",
    "    n_fft = 1024\n",
    "    hop_length = 512\n",
    "    win_length = 1024\n",
    "    X_linear = np.exp(X/10)\n",
    "    X_logMel = librosa.power_to_db(np.square(np.abs(librosa.feature.melspectrogram(y=None,S = X_linear ,sr =fs, n_fft = n_fft, hop_length = hop_length, win_length = win_length, window='hann', dtype = np.complex256 ))))\n",
    "    #X_MFCC = librosa.feature.mfcc(y=None, sr=fs, S=X_melSpect, n_mfcc=20)\n",
    "    return X_logMel\n",
    "\n",
    "def wavToSTFT(inFile, outFile):\n",
    "    fs = 16000\n",
    "    n_fft = 1024\n",
    "    hop_length = 512\n",
    "    win_length = 1024\n",
    "    x,sr = readAudio(inFile) \n",
    "    X = calc_spec(x)\n",
    "    saveSpectrogram(X, outFile)\n",
    "    return\n",
    "\n",
    "def createSTFT(dir_wavs, filenum, dir_specs):\n",
    "    i = 1\n",
    "    while i<= filenum:\n",
    "        wavToSTFT(dir_wavs+str(i)+'.wav', dir_specs+str(i)+'.npy')\n",
    "        i=i+1\n",
    "        \n",
    "    print(\"Completed conversion to spectrograms\")\n",
    "    return\n",
    "\n",
    "def reshape_3D_mat(x):\n",
    "    count = 0\n",
    "    Nrows = x.shape[0]\n",
    "    new=[]\n",
    "    while count < Nrows:\n",
    "        \n",
    "        r_count = 0\n",
    "        while r_count < x.shape[2]:\n",
    "            new.append(x[count,:,r_count])\n",
    "            r_count = r_count + 1\n",
    "        count = count+1\n",
    "    new = np.array(new)\n",
    "    return new\n",
    "\n",
    "\n",
    "def createDataSpeech(df, filenum, file):\n",
    "    temp = df.iloc[0]\n",
    "    Y = []\n",
    "    i = 0\n",
    "    k=0\n",
    "    X = []\n",
    "    #print(df.shape[0])\n",
    "    while i <= filenum-1 :\n",
    "        X_train = read_from_npy(file+str(i+1)+\".npy\")\n",
    "        X_train = stftToLogMel(X_train)\n",
    "        #print(X_train.shape)\n",
    "        H = X_train.shape[1]\n",
    "        X.append(X_train)\n",
    "        buffer = np.array([[0,0,1]]*H).T\n",
    "        #print(y_train.shape)\n",
    "        filename = temp['filename']\n",
    "        while filename == temp['filename']:\n",
    "            #print(Y)\n",
    "            filename = temp['filename']\n",
    "            t_start = temp['onset']\n",
    "            t_end = temp['offset']\n",
    "            #print(\"Number of frames\",conv_to_frame(t_end,H)-conv_to_frame(t_start,H))\n",
    "            #print(temp)\n",
    "            for j in range(conv_to_frame(t_start,H),conv_to_frame(t_end,H)):\n",
    "                buffer[1,j] = 1\n",
    "                buffer[2,j] = 0\n",
    "            if k<df.shape[0]-1:\n",
    "                k=k+1\n",
    "                #print(k)\n",
    "                temp = df.iloc[k]\n",
    "            else:\n",
    "                break\n",
    "        i=i+1\n",
    "        Y.append(buffer)\n",
    "        \n",
    "    X = np.array(X)\n",
    "    Y = np.array(Y)\n",
    "    #X = reshape_3D_mat(X)\n",
    "    #Y = reshape_3D_mat(Y)\n",
    "    return X, Y\n",
    "\n",
    "def createDataMusic(df, filenum, file):\n",
    "    temp = df.iloc[0]\n",
    "    Y = []\n",
    "    i = 0\n",
    "    k=0\n",
    "    X = []\n",
    "    #print(df.shape[0])\n",
    "    while i <= filenum-1 :\n",
    "        X_train = read_from_npy(file+str(i+1)+\".npy\")\n",
    "        X_train = stftToLogMel(X_train)\n",
    "        #print(X_train.shape)\n",
    "        H = X_train.shape[1]\n",
    "        X.append(X_train)\n",
    "        buffer = np.array([[0,0,1]]*H).T\n",
    "        #print(y_train.shape)\n",
    "        filename = temp['filename']\n",
    "        while filename == temp['filename']:\n",
    "            #print(Y)\n",
    "            filename = temp['filename']\n",
    "            t_start = temp['onset']\n",
    "            t_end = temp['offset']\n",
    "            #print(\"Number of frames\",conv_to_frame(t_end,H)-conv_to_frame(t_start,H))\n",
    "            #print(temp)\n",
    "            for j in range(conv_to_frame(t_start,H),conv_to_frame(t_end,H)):\n",
    "                buffer[0,j] = 1\n",
    "                buffer[2,j] = 0\n",
    "            if k<df.shape[0]-1:\n",
    "                k=k+1\n",
    "                #print(k)\n",
    "                temp = df.iloc[k]\n",
    "            else:\n",
    "                break\n",
    "        i=i+1\n",
    "        Y.append(buffer)\n",
    "        \n",
    "    X = np.array(X)\n",
    "    Y = np.array(Y)\n",
    "    #X = reshape_3D_mat(X)\n",
    "    #Y = reshape_3D_mat(Y)\n",
    "    return X, Y\n",
    "\n",
    "def createDataBoth(df, filenum, file):\n",
    "    temp = df.iloc[0]\n",
    "    Y = []\n",
    "    i = 0\n",
    "    k=0\n",
    "    X = []\n",
    "    #print(df.shape[0])\n",
    "    while i <= filenum-1 :\n",
    "        X_train = read_from_npy(file+str(i+1)+\".npy\")\n",
    "        X_train = stftToLogMel(X_train)\n",
    "        #print(X_train.shape)\n",
    "        H = X_train.shape[1]\n",
    "        X.append(X_train)\n",
    "        buffer = np.array([[0,0,1]]*H).T\n",
    "        #print(y_train.shape)\n",
    "        filename = temp['filename']\n",
    "        while filename == temp['filename']:\n",
    "            #print(Y)\n",
    "            filename = temp['filename']\n",
    "            t_start = temp['onset']\n",
    "            t_end = temp['offset']\n",
    "            label = temp['class']\n",
    "            #print(\"Number of frames\",conv_to_frame(t_end,H)-conv_to_frame(t_start,H))\n",
    "            #print(temp)\n",
    "            for j in range(conv_to_frame(t_start,H),conv_to_frame(t_end,H)):\n",
    "                if label == 'music':\n",
    "                    buffer[0,j] = 1\n",
    "                    buffer[2,j] = 0\n",
    "                else:\n",
    "                    buffer[1,j] = 1\n",
    "                    buffer[2,j] = 0\n",
    "            if k<df.shape[0]-1:\n",
    "                k=k+1\n",
    "                #print(k)\n",
    "                temp = df.iloc[k]\n",
    "            else:\n",
    "                break\n",
    "        i=i+1\n",
    "        Y.append(buffer)\n",
    "        \n",
    "    X = np.array(X)\n",
    "    Y = np.array(Y)\n",
    "    #X = reshape_3D_mat(X)\n",
    "    #Y = reshape_3D_mat(Y)\n",
    "    return X, Y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04fb395c",
   "metadata": {},
   "source": [
    "# main function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "209849a4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(497, 128, 313)\n",
      "(592, 128, 313)\n",
      "(587, 128, 313)\n",
      "(1676, 128, 313)\n",
      "(1676, 313, 3)\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    \n",
    "    '''The segments of code not used are commented below. The data preprocessing was done in stages, saving the files\n",
    "    between intermediate stages  so as to reduce computation times and file load times.\n",
    "    FIRST STAGE - \n",
    "    Converting stereo files to mono files.\n",
    "    \n",
    "    SECOND STAGE - \n",
    "    Storing the information in converted .wav files to .npy files as loading and working with .npy files is faster.\n",
    "    \n",
    "    THIRD STAGE - \n",
    "    Converting the hour long files to 10s samples and storing as .wav files. Here we also generated the timestamps\n",
    "    and stored in .csv files.\n",
    "    \n",
    "    FOURTH STAGE - \n",
    "    Generate the STFTs for all the .wav files and store them as .npy files.\n",
    "    \n",
    "    FIFTH STAGE - \n",
    "    Load the STFTs, convert to Log Melspectrograms and concatenate to create the test data corresponding to Music Speech \n",
    "    and mixed files. Here we also generated the labels using the .csv file stored in stage 3.\n",
    "    \n",
    "    SIXTH STAGE - \n",
    "    The converted files are finally concatenated to form X_train and Y_train and are stored as .npy files. These files\n",
    "    are given as input to the model for training.'''\n",
    "    \n",
    "    # conv_to_mono(\"./Training/wav_files/speech3.wav\",\"./Training/wav_files/speech3_mono.wav\")\n",
    "    # store_to_npy(\"music1_mono.wav\",\"music1.npy\")\n",
    "    # store_to_npy(\"./Training/wav_files/speech3_mono.wav\",\"./Training/speech3.npy\")\n",
    "    # music1 = read_from_npy(\"./Training/music1.npy\")\n",
    "    # speech1 = read_from_npy(\"./Training/speech3.npy\")\n",
    "    # temp = music1[0:159999]\n",
    "    # write_npy_to_wav(temp,\"music_1.wav\")\n",
    "    \n",
    "    # mLen = int(np.ceil(2/3*music1.shape[0]))  # number of samples for only music\n",
    "    # sLen = int(np.ceil(2/3*speech1.shape[0])) # number of samples for only speech\n",
    "    # bmLen = music1.shape[0] - mLen            # number of samples of music for both music and speech\n",
    "    # bsLen = speech1.shape[0] - sLen           # number of samples of speech for both music and speech\n",
    "    # print(mLen,sLen, msmLen, mssLen)\n",
    "    wav_dir = './labels_wav/'\n",
    "    spectrogram_dir = './labels_spectrogram/'\n",
    "    music_dir = \"music/\"\n",
    "    speech_dir = \"speech/\"\n",
    "    both_dir = \"both/\"\n",
    "    dirname = spectrogram_dir+speech_dir\n",
    "    #temp = music1[0:mLen-1]\n",
    "    #music_file_num = convert_to_segments(temp, wav_dir+music_dir, \"music_noisy\",'music') \n",
    "    #temp = speech1[0:sLen-1]\n",
    "    #speech_file_num = convert_to_segments(temp, wav_dir+speech_dir,\"speech_noisy\",'speech')\n",
    "    \n",
    "    #temp1 = music1[mLen:]\n",
    "    #temp2 = speech1[sLen:]\n",
    "    #both_file_num = convert_to_mixed_segments(temp1,temp2,wav_dir+both_dir,\"music+speech_noisy\")\n",
    "    #np.save('./file_counts.npy', np.array([music_file_num, speech_file_num, both_file_num]))\n",
    "    \n",
    "    \n",
    "    arr = np.load('./file_counts.npy')\n",
    "    music_file_num = arr[0]\n",
    "    speech_file_num = arr[1]\n",
    "    both_file_num = arr[2]\n",
    "    \n",
    "    #createSTFT(wav_dir+music_dir+'/music_noisy', music_file_num, spectrogram_dir+music_dir+'/music_noisy')\n",
    "    #createSTFT(wav_dir+speech_dir+'/speech_noisy', speech_file_num, spectrogram_dir+speech_dir+'/speech_noisy')\n",
    "    #createSTFT(wav_dir+both_dir+'/music+speech_noisy', both_file_num, spectrogram_dir+both_dir+'/both_noisy')\n",
    "    '''labels_dir_speech = './labels_wav/speech/labels.csv'\n",
    "    labels_dir_music = './labels_wav/music/labels.csv'\n",
    "    labels_dir_both = './labels_wav/both/labels.csv'\n",
    "    df1 = pd.read_csv(labels_dir_speech)\n",
    "    file = spectrogram_dir+speech_dir+\"speech_noisy\"\n",
    "    X_speech, Y_speech = createDataSpeech(df1,speech_file_num, file)\n",
    "    df2 = pd.read_csv(labels_dir_music)\n",
    "    file = spectrogram_dir+music_dir+\"music_noisy\"\n",
    "    X_music, Y_music = createDataSpeech(df2,music_file_num, file)\n",
    "    df3 = pd.read_csv(labels_dir_both)\n",
    "    file = spectrogram_dir+both_dir+\"both_noisy\"\n",
    "    X_both, Y_both = createDataBoth(df3, both_file_num, file)\n",
    "    np.save('./Training/X_speech.npy',X_speech)\n",
    "    np.save('./Training/Y_speech.npy',Y_speech)\n",
    "    np.save('./Training/X_music.npy',X_music)\n",
    "    np.save('./Training/Y_music.npy',Y_music)\n",
    "    np.save('./Training/X_both.npy',X_both)\n",
    "    np.save('./Training/Y_both.npy',Y_both)'''\n",
    "    X_speech = np.load('./Training/X_speech.npy')\n",
    "    Y_speech = np.load('./Training/Y_speech.npy')\n",
    "    X_music = np.load('./Training/X_music.npy')\n",
    "    Y_music = np.load('./Training/Y_music.npy')\n",
    "    X_both = np.load('./Training/X_both.npy')\n",
    "    Y_both = np.load('./Training/Y_both.npy')\n",
    "    \n",
    "    print(X_speech.shape)\n",
    "    print(X_music.shape)\n",
    "    print(X_both.shape)\n",
    "    X_train = np.concatenate((X_speech, X_music, X_both), axis=0)\n",
    "    print(X_train.shape)\n",
    "    Y_train = np.concatenate((Y_speech, Y_music, Y_both), axis=0)\n",
    "    Y_train = np.swapaxes(Y_train,2,1)\n",
    "    print(Y_train.shape)\n",
    "    np.save('./Training/X_train.npy',X_train)\n",
    "    np.save('./Training/Y_train.npy',Y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8663d929",
   "metadata": {},
   "source": [
    "# Test Data Creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ec224eef",
   "metadata": {},
   "outputs": [],
   "source": [
    "def createTestInputSet(test_path):\n",
    "    i = 0\n",
    "    X = []\n",
    "    while i<=9:\n",
    "        file = test_path+'test_sample-'+str(i)+'.npy'\n",
    "        x = np.load(file)\n",
    "        x = convToLinear(x)\n",
    "        x = stftToLogMel(x)\n",
    "        X.append(x)\n",
    "        i = i+1\n",
    "\n",
    "    X = np.array(X)    \n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "cb69cb4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10, 128, 313)\n"
     ]
    }
   ],
   "source": [
    "test_path = './evaluation/mocktest_set/spectrogram/'\n",
    "x = createTestInputSet(test_path)\n",
    "print(x.shape)\n",
    "np.save('./evaluation/mocktest_set/xdemo.npy',x)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
